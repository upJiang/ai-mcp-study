"""MCP æ€§èƒ½åˆ†æå·¥å…· - EXPLAIN åˆ†æå’Œæ…¢æŸ¥è¯¢æ£€æµ‹"""

import asyncio
import json
import logging
import time
from typing import Any

from mcp.server import Server

logger = logging.getLogger(__name__)


def register_performance_tools(server: Server, db_ops: Any) -> None:
    """
    æ³¨å†Œæ€§èƒ½åˆ†æç›¸å…³çš„ MCP Tools

    Args:
        server: MCP Server å®ä¾‹
        db_ops: DatabaseOperations å®ä¾‹
    """

    @server.tool()
    async def explain_query(
        database: str,
        query: str,
        format: str = "traditional"
    ) -> dict[str, Any]:
        """
        ä½¿ç”¨ EXPLAIN åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’

        Args:
            database: æ•°æ®åº“åç§°
            query: SQL æŸ¥è¯¢è¯­å¥ï¼ˆä»…æ”¯æŒ SELECTï¼‰
            format: EXPLAIN æ ¼å¼ï¼ˆtraditional/json/treeï¼Œé»˜è®¤ traditionalï¼‰

        Returns:
            EXPLAIN åˆ†æç»“æœå’Œä¼˜åŒ–å»ºè®®
        """
        try:
            # å‚æ•°éªŒè¯
            if format not in ("traditional", "json", "tree"):
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„æ ¼å¼: {format}ï¼Œæ”¯æŒçš„æ ¼å¼: traditional, json, tree"
                }

            # éªŒè¯æ˜¯ SELECT æŸ¥è¯¢
            query_upper = query.strip().upper()
            if not query_upper.startswith("SELECT"):
                return {
                    "success": False,
                    "error": "åªæ”¯æŒåˆ†æ SELECT æŸ¥è¯¢"
                }

            # æ„å»º EXPLAIN æŸ¥è¯¢
            if format == "json":
                explain_query = f"EXPLAIN FORMAT=JSON {query}"
            elif format == "tree":
                explain_query = f"EXPLAIN FORMAT=TREE {query}"
            else:
                explain_query = f"EXPLAIN {query}"

            # æ‰§è¡Œ EXPLAINï¼ˆä¸ä½¿ç”¨ limitï¼ŒEXPLAIN ä¸è¿”å›å¤§é‡æ•°æ®ï¼‰
            explain_result = await asyncio.to_thread(
                db_ops.execute_query,
                database,
                explain_query,
                None,
                None,  # EXPLAIN ä¸éœ€è¦ limit
                "explain_query"
            )

            if not explain_result.get("success"):
                return explain_result

            # åˆ†æ EXPLAIN ç»“æœ
            analysis = _analyze_explain(explain_result.get("data", []), format)

            # åŒæ—¶æ‰§è¡Œå®é™…æŸ¥è¯¢ä»¥è·å–æ‰§è¡Œæ—¶é—´
            start_time = time.time()
            actual_result = await asyncio.to_thread(
                db_ops.execute_query,
                database,
                query,
                None,
                10,  # åªå– 10 è¡Œæµ‹è¯•æ€§èƒ½
                "explain_query_test"
            )
            execution_time = time.time() - start_time

            logger.info(
                f"EXPLAIN åˆ†æ: {database}.{query[:50]}... "
                f"(æ‰§è¡Œæ—¶é—´: {execution_time:.3f}s)"
            )

            return {
                "success": True,
                "database": database,
                "query": query,
                "format": format,
                "explain_result": explain_result.get("data", []),
                "execution_time": round(execution_time, 4),
                "analysis": analysis,
                "recommendations": _generate_recommendations(
                    explain_result.get("data", []),
                    execution_time,
                    format
                )
            }

        except Exception as e:
            logger.error(f"EXPLAIN åˆ†æå¤±è´¥ [{database}]: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "database": database
            }

    @server.tool()
    async def analyze_slow_query(
        database: str,
        query: str,
        threshold: float = 1.0
    ) -> dict[str, Any]:
        """
        åˆ†ææ…¢æŸ¥è¯¢å¹¶æä¾›ä¼˜åŒ–å»ºè®®

        Args:
            database: æ•°æ®åº“åç§°
            query: SQL æŸ¥è¯¢è¯­å¥
            threshold: æ…¢æŸ¥è¯¢é˜ˆå€¼ï¼ˆç§’ï¼Œé»˜è®¤ 1.0ï¼‰

        Returns:
            æ…¢æŸ¥è¯¢åˆ†æç»“æœå’Œä¼˜åŒ–å»ºè®®
        """
        try:
            # å‚æ•°éªŒè¯
            if threshold < 0.1 or threshold > 60:
                return {
                    "success": False,
                    "error": "threshold å¿…é¡»åœ¨ 0.1-60 ç§’ä¹‹é—´"
                }

            # æ‰§è¡ŒæŸ¥è¯¢å¹¶æµ‹é‡æ—¶é—´
            start_time = time.time()
            result = await asyncio.to_thread(
                db_ops.execute_query,
                database,
                query,
                None,
                100,  # é™åˆ¶ 100 è¡Œç”¨äºæ€§èƒ½æµ‹è¯•
                "analyze_slow_query"
            )
            execution_time = time.time() - start_time

            if not result.get("success"):
                return result

            # åˆ¤æ–­æ˜¯å¦ä¸ºæ…¢æŸ¥è¯¢
            is_slow = execution_time >= threshold

            # è·å– EXPLAIN åˆ†æ
            explain_query = f"EXPLAIN FORMAT=JSON {query}"
            explain_result = await asyncio.to_thread(
                db_ops.execute_query,
                database,
                explain_query,
                None,
                None,
                "analyze_slow_query_explain"
            )

            # åˆ†æç»“æœ
            analysis = {
                "is_slow_query": is_slow,
                "execution_time": round(execution_time, 4),
                "threshold": threshold,
                "row_count": result.get("row_count", 0),
                "rows_per_second": round(result.get("row_count", 0) / execution_time, 2) if execution_time > 0 else 0
            }

            # å¦‚æœæ˜¯æ…¢æŸ¥è¯¢ï¼Œæä¾›è¯¦ç»†åˆ†æ
            if is_slow:
                logger.warning(
                    f"æ£€æµ‹åˆ°æ…¢æŸ¥è¯¢: {database}.{query[:50]}... "
                    f"(æ‰§è¡Œæ—¶é—´: {execution_time:.3f}s, é˜ˆå€¼: {threshold}s)"
                )

                # æå– EXPLAIN æ•°æ®
                explain_data = []
                if explain_result.get("success"):
                    explain_data = explain_result.get("data", [])

                recommendations = _generate_slow_query_recommendations(
                    query,
                    execution_time,
                    explain_data
                )

                return {
                    "success": True,
                    "database": database,
                    "query": query,
                    "analysis": analysis,
                    "explain_result": explain_data,
                    "recommendations": recommendations,
                    "severity": _classify_slow_query_severity(execution_time, threshold)
                }
            else:
                logger.info(
                    f"æŸ¥è¯¢æ€§èƒ½æ­£å¸¸: {database}.{query[:50]}... "
                    f"(æ‰§è¡Œæ—¶é—´: {execution_time:.3f}s)"
                )

                return {
                    "success": True,
                    "database": database,
                    "query": query,
                    "analysis": analysis,
                    "message": f"æŸ¥è¯¢æ€§èƒ½æ­£å¸¸ï¼ˆ{execution_time:.3f}s < {threshold}sï¼‰"
                }

        except Exception as e:
            logger.error(f"æ…¢æŸ¥è¯¢åˆ†æå¤±è´¥ [{database}]: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "database": database
            }


def _analyze_explain(explain_data: list[dict[str, Any]], format: str) -> dict[str, Any]:
    """åˆ†æ EXPLAIN ç»“æœ"""
    if not explain_data:
        return {"error": "EXPLAIN ç»“æœä¸ºç©º"}

    analysis = {
        "total_rows": 0,
        "using_index": False,
        "using_temporary": False,
        "using_filesort": False,
        "full_table_scan": False,
        "join_type": [],
        "tables_scanned": []
    }

    try:
        if format == "json":
            # JSON æ ¼å¼çš„ EXPLAIN åˆ†æ
            if explain_data and "EXPLAIN" in explain_data[0]:
                json_data = json.loads(explain_data[0]["EXPLAIN"])
                # ç®€åŒ–å¤„ç†ï¼Œæå–å…³é”®ä¿¡æ¯
                analysis["format"] = "json"
                analysis["details"] = json_data
        else:
            # Traditional æ ¼å¼çš„ EXPLAIN åˆ†æ
            for row in explain_data:
                # è¡¨å
                if "table" in row:
                    analysis["tables_scanned"].append(row["table"])

                # æ‰«æè¡Œæ•°
                if "rows" in row:
                    analysis["total_rows"] += int(row.get("rows", 0) or 0)

                # JOIN ç±»å‹
                if "type" in row:
                    join_type = row["type"]
                    analysis["join_type"].append(join_type)

                    # æ£€æµ‹å…¨è¡¨æ‰«æ
                    if join_type in ("ALL", "index"):
                        analysis["full_table_scan"] = True

                # Extra ä¿¡æ¯
                extra = row.get("Extra", "")
                if "Using index" in extra:
                    analysis["using_index"] = True
                if "Using temporary" in extra:
                    analysis["using_temporary"] = True
                if "Using filesort" in extra:
                    analysis["using_filesort"] = True

    except Exception as e:
        logger.error(f"åˆ†æ EXPLAIN ç»“æœæ—¶å‡ºé”™: {str(e)}")
        analysis["parse_error"] = str(e)

    return analysis


def _generate_recommendations(
    explain_data: list[dict[str, Any]],
    execution_time: float,
    format: str
) -> list[str]:
    """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    recommendations = []

    analysis = _analyze_explain(explain_data, format)

    # å…¨è¡¨æ‰«æè­¦å‘Š
    if analysis.get("full_table_scan"):
        recommendations.append(
            "âš ï¸ æ£€æµ‹åˆ°å…¨è¡¨æ‰«æï¼ˆtype=ALLï¼‰ï¼Œå»ºè®®æ·»åŠ é€‚å½“çš„ç´¢å¼•"
        )

    # ä¸´æ—¶è¡¨è­¦å‘Š
    if analysis.get("using_temporary"):
        recommendations.append(
            "âš ï¸ ä½¿ç”¨äº†ä¸´æ—¶è¡¨ï¼ˆUsing temporaryï¼‰ï¼Œå¯èƒ½å½±å“æ€§èƒ½ï¼Œè€ƒè™‘ä¼˜åŒ–æŸ¥è¯¢æˆ–æ·»åŠ ç´¢å¼•"
        )

    # æ–‡ä»¶æ’åºè­¦å‘Š
    if analysis.get("using_filesort"):
        recommendations.append(
            "âš ï¸ ä½¿ç”¨äº†æ–‡ä»¶æ’åºï¼ˆUsing filesortï¼‰ï¼Œè€ƒè™‘åœ¨ ORDER BY å­—æ®µä¸Šæ·»åŠ ç´¢å¼•"
        )

    # æ‰«æè¡Œæ•°è­¦å‘Š
    total_rows = analysis.get("total_rows", 0)
    if total_rows > 10000:
        recommendations.append(
            f"âš ï¸ æ‰«æè¡Œæ•°è¾ƒå¤šï¼ˆ{total_rows} è¡Œï¼‰ï¼Œå»ºè®®ä¼˜åŒ–æŸ¥è¯¢æ¡ä»¶æˆ–æ·»åŠ ç´¢å¼•"
        )

    # æ‰§è¡Œæ—¶é—´è­¦å‘Š
    if execution_time > 1.0:
        recommendations.append(
            f"âš ï¸ æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼ˆ{execution_time:.3f}sï¼‰ï¼Œå»ºè®®è¿›è¡Œä¼˜åŒ–"
        )

    # ä½¿ç”¨ç´¢å¼•çš„å¥½æ¶ˆæ¯
    if analysis.get("using_index"):
        recommendations.append(
            "âœ… æŸ¥è¯¢ä½¿ç”¨äº†ç´¢å¼•ï¼ˆUsing indexï¼‰ï¼Œæ€§èƒ½è¾ƒå¥½"
        )

    if not recommendations:
        recommendations.append("âœ… æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’æ­£å¸¸ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®")

    return recommendations


def _generate_slow_query_recommendations(
    query: str,
    execution_time: float,
    explain_data: list[dict[str, Any]]
) -> list[str]:
    """ä¸ºæ…¢æŸ¥è¯¢ç”Ÿæˆè¯¦ç»†çš„ä¼˜åŒ–å»ºè®®"""
    recommendations = []

    # åŸºç¡€å»ºè®®
    recommendations.append(f"ğŸŒ æ…¢æŸ¥è¯¢æ£€æµ‹ï¼šæ‰§è¡Œæ—¶é—´ {execution_time:.3f} ç§’")

    # EXPLAIN åˆ†æå»ºè®®
    if explain_data:
        analysis = _analyze_explain(explain_data, "traditional")

        if analysis.get("full_table_scan"):
            recommendations.append(
                "ğŸ“Œ ä¼˜å…ˆå»ºè®®ï¼šæ·»åŠ ç´¢å¼•é¿å…å…¨è¡¨æ‰«æ\n"
                "   - æ£€æŸ¥ WHERE æ¡ä»¶ä¸­çš„å­—æ®µ\n"
                "   - ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºå¤åˆç´¢å¼•"
            )

        if analysis.get("using_temporary"):
            recommendations.append(
                "ğŸ“Œ ä¼˜åŒ–å»ºè®®ï¼šé¿å…ä½¿ç”¨ä¸´æ—¶è¡¨\n"
                "   - ç®€åŒ– GROUP BY å­å¥\n"
                "   - ä¸º GROUP BY å­—æ®µæ·»åŠ ç´¢å¼•\n"
                "   - è€ƒè™‘é‡å†™æŸ¥è¯¢é€»è¾‘"
            )

        if analysis.get("using_filesort"):
            recommendations.append(
                "ğŸ“Œ ä¼˜åŒ–å»ºè®®ï¼šé¿å…æ–‡ä»¶æ’åº\n"
                "   - ä¸º ORDER BY å­—æ®µæ·»åŠ ç´¢å¼•\n"
                "   - ç¡®ä¿ç´¢å¼•é¡ºåºä¸ ORDER BY ä¸€è‡´"
            )

        # æ‰«æè¡Œæ•°å»ºè®®
        total_rows = analysis.get("total_rows", 0)
        if total_rows > 50000:
            recommendations.append(
                f"ğŸ“Œ æ•°æ®é‡å»ºè®®ï¼šæ‰«æäº† {total_rows} è¡Œæ•°æ®\n"
                "   - æ·»åŠ æ›´ç²¾ç¡®çš„ WHERE æ¡ä»¶\n"
                "   - è€ƒè™‘åˆ†é¡µæŸ¥è¯¢\n"
                "   - ä½¿ç”¨ LIMIT é™åˆ¶è¿”å›è¡Œæ•°"
            )

    # æŸ¥è¯¢è¯­å¥åˆ†æ
    query_upper = query.upper()

    # æ£€æµ‹æ˜¯å¦ç¼ºå°‘ WHERE
    if "WHERE" not in query_upper and "JOIN" in query_upper:
        recommendations.append(
            "ğŸ“Œ æŸ¥è¯¢ç»“æ„å»ºè®®ï¼šç¼ºå°‘ WHERE æ¡ä»¶\n"
            "   - æ·»åŠ é€‚å½“çš„è¿‡æ»¤æ¡ä»¶\n"
            "   - é¿å…è¿”å›ä¸å¿…è¦çš„æ•°æ®"
        )

    # æ£€æµ‹æ˜¯å¦ä½¿ç”¨äº† SELECT *
    if "SELECT *" in query_upper:
        recommendations.append(
            "ğŸ“Œ å­—æ®µé€‰æ‹©å»ºè®®ï¼šé¿å…ä½¿ç”¨ SELECT *\n"
            "   - åªæŸ¥è¯¢éœ€è¦çš„å­—æ®µ\n"
            "   - å‡å°‘ç½‘ç»œä¼ è¾“å’Œå†…å­˜å ç”¨"
        )

    # æ£€æµ‹æ˜¯å¦æœ‰å­æŸ¥è¯¢
    if query.count("SELECT") > 1:
        recommendations.append(
            "ğŸ“Œ å­æŸ¥è¯¢ä¼˜åŒ–ï¼šè€ƒè™‘ä¼˜åŒ–å­æŸ¥è¯¢\n"
            "   - å°è¯•ä½¿ç”¨ JOIN æ›¿ä»£å­æŸ¥è¯¢\n"
            "   - ç¡®ä¿å­æŸ¥è¯¢æœ‰é€‚å½“çš„ç´¢å¼•\n"
            "   - è€ƒè™‘ä½¿ç”¨ä¸´æ—¶è¡¨æ‹†åˆ†å¤æ‚æŸ¥è¯¢"
        )

    return recommendations


def _classify_slow_query_severity(execution_time: float, threshold: float) -> str:
    """åˆ†ç±»æ…¢æŸ¥è¯¢ä¸¥é‡ç¨‹åº¦"""
    ratio = execution_time / threshold

    if ratio >= 10:
        return "critical"  # ä¸¥é‡ï¼ˆè¶…è¿‡é˜ˆå€¼ 10 å€ï¼‰
    elif ratio >= 5:
        return "high"      # é«˜ï¼ˆè¶…è¿‡é˜ˆå€¼ 5 å€ï¼‰
    elif ratio >= 2:
        return "medium"    # ä¸­ï¼ˆè¶…è¿‡é˜ˆå€¼ 2 å€ï¼‰
    else:
        return "low"       # ä½ï¼ˆç•¥è¶…é˜ˆå€¼ï¼‰
